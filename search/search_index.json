{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AWS Data Protection Workshops If you are considering protecting data in your AWS environment using methods such as encryption or certificate management, these workshops can help you learn in depth. We will be using the Cloud9 IDE environment and a combination of Python code and AWS console access for these workshops. Ubiquitous Encryption Data encryption provides a strong layer of security to protect data that you store within AWS services. AWS services can help you achieve ubiquitous encryption for data in transit as well as data at rest. Prerequisites AWS Account If you are participating in this workshop as part of an AWS event, pre-provisioned temporary accounts that are specifically initialized for this workshop might be provided by the organizers. To access your temporary account you will receive a 12-digit hash code that can be used at the AWS Event Engine Site . You will not need a username and password. If you wish to participate in this workshop without a pre-provisioned temporary account, please see the AWS Initialization and tear down section below. Browser These workshops assume that you are using the Cloud9 IDE environment . We recommend you use the latest version of Chrome or Firefox to complete this workshop. Knowledge Of Python Programming Language Basic python knowledge is sufficient to consume these workshops. Setup Workshop Environment Navigate to the Cloud9 service within your AWS console Open the Cloud9 IDE environment called workshop-environment . It takes about 30 seconds for the environment to start up. In the Cloud9 IDE environment you will find a folder called data-protection in the folder pane on the left side of the screen Right-click (on MacOS: control-click) the file named environment-setup.sh in the IDE and select Run This script takes about a minute to complete In the runner window below you should see SUCCESS: installed python dependencies followed by a list of the installed packages Workshops These workshops demonstrates server side encryption, client side encryption and certfificate management concepts within AWS. For example : How do I put an object on S3 with server side encryption ? How do I use aws encryption sdk to encrypt data in my application before sending the data to an AWS service ? What is Data Key Caching ? How can I generate X.509 certificates with AWS Certificate Manager to enable TLS on my load balancer ? How do I use AWS Certificate Manager to generate a private certificate authority ? Title Description Learning Time Teaching Time With Discussion Level 200: Server Side Encryption This workshop demonstrates server side encryption on S3 15 min 30 min Level 200: Client Side Encryption This workshop demonstrates client side encryption 15 min 30 min Level 200: Client Side Encryption With Data Key Caching This workshop demonstrates client side encryption with data key caching 15 min 30 min Level 300: Creating Private Certs ACM Private Certificate Authority - Mode-1 This workshop demonstrates how you create a AWS Certificate Manager private certificate authority(PCA) and use ACM PCA to sign a CSR to create a private certificate 40 mins 1 hour Level 300: Creating Private Certs ACM Private Certificate Authority - Mode-2 This workshop demonstrates how you create a AWS Certificate Manager private certificate authority and use this CA to create private X.509 certififcates for a private domain 40 mins 1 hour NOTE: The ACM PCA use cases (the latter 2) can only be run within the VPC where the ALB is deployed as a private DNS name space is used. This will work within the Cloud9 IDE but not from machines that are outside of the VPC. AWS Initialization tear down IMPORTANT! This section is only relevant if you are not using a pre-provisioned account. The resources used in this workshop will incur charges in the AWS account used if not torn down according to the procedure outlined below You can use a personal account or create a new AWS account to ensure you have the neccessary access. This should not be an AWS account from the company you work for. Please note that creating an AWS account takes time (credit card validation, etc.) and is not recommended when participating in the workshop during a time constrained event. Region Support Since these workshops use the Cloud9 IDE, you can use run these workshops in the following regions where the AWS Cloud9 service is available : N.Virginia (us-east-1) Ohio (us-east-2) Oregon (us-west-2) Ireland (eu-west-1) * Singapore (ap-southeast-1) Cloudformation templates for initial environment setup Please download the Data Protection Workshop cloudformation stack and launch it in your AWS account as this is required for all the workshops in this repository. To launch the stack you must go to the AWS Console and navigate to the CloudFormation service where you can choose Create Stack and upload the Cloudformation stack for the workshop. You provide a name for the stack and keep clicking next until you get to the point where it says: I acknowledge that AWS CloudFormation might create IAM resources with custom names. Acknowledge the above statement by clicking on the check box and then click on the Create button The above stack creates an Cloud9 IDE environment called workshop-environment . In addition a VPC with two subnets and an internet gateway is also created. Tear down Cloudformation stack After you have completed the workshop, you need to tear down the stack by navigating to the CloudFormation service in the AWS console and selecting the stack name you chose when launching the stack. Choose the delete action and wait for the process to complete. Note that it can take a few minutes for the stack to clean up its resources. License Summary This sample code is made available under a modified MIT license. See the LICENSE file.","title":"Overview"},{"location":"#aws-data-protection-workshops","text":"If you are considering protecting data in your AWS environment using methods such as encryption or certificate management, these workshops can help you learn in depth. We will be using the Cloud9 IDE environment and a combination of Python code and AWS console access for these workshops.","title":"AWS Data Protection Workshops"},{"location":"#ubiquitous-encryption","text":"Data encryption provides a strong layer of security to protect data that you store within AWS services. AWS services can help you achieve ubiquitous encryption for data in transit as well as data at rest.","title":"Ubiquitous Encryption"},{"location":"#prerequisites","text":"","title":"Prerequisites"},{"location":"#aws-account","text":"If you are participating in this workshop as part of an AWS event, pre-provisioned temporary accounts that are specifically initialized for this workshop might be provided by the organizers. To access your temporary account you will receive a 12-digit hash code that can be used at the AWS Event Engine Site . You will not need a username and password. If you wish to participate in this workshop without a pre-provisioned temporary account, please see the AWS Initialization and tear down section below.","title":"AWS Account"},{"location":"#browser","text":"These workshops assume that you are using the Cloud9 IDE environment . We recommend you use the latest version of Chrome or Firefox to complete this workshop.","title":"Browser"},{"location":"#knowledge-of-python-programming-language","text":"Basic python knowledge is sufficient to consume these workshops.","title":"Knowledge Of Python Programming Language"},{"location":"#setup-workshop-environment","text":"Navigate to the Cloud9 service within your AWS console Open the Cloud9 IDE environment called workshop-environment . It takes about 30 seconds for the environment to start up. In the Cloud9 IDE environment you will find a folder called data-protection in the folder pane on the left side of the screen Right-click (on MacOS: control-click) the file named environment-setup.sh in the IDE and select Run This script takes about a minute to complete In the runner window below you should see SUCCESS: installed python dependencies followed by a list of the installed packages","title":"Setup Workshop Environment"},{"location":"#workshops","text":"These workshops demonstrates server side encryption, client side encryption and certfificate management concepts within AWS. For example : How do I put an object on S3 with server side encryption ? How do I use aws encryption sdk to encrypt data in my application before sending the data to an AWS service ? What is Data Key Caching ? How can I generate X.509 certificates with AWS Certificate Manager to enable TLS on my load balancer ? How do I use AWS Certificate Manager to generate a private certificate authority ? Title Description Learning Time Teaching Time With Discussion Level 200: Server Side Encryption This workshop demonstrates server side encryption on S3 15 min 30 min Level 200: Client Side Encryption This workshop demonstrates client side encryption 15 min 30 min Level 200: Client Side Encryption With Data Key Caching This workshop demonstrates client side encryption with data key caching 15 min 30 min Level 300: Creating Private Certs ACM Private Certificate Authority - Mode-1 This workshop demonstrates how you create a AWS Certificate Manager private certificate authority(PCA) and use ACM PCA to sign a CSR to create a private certificate 40 mins 1 hour Level 300: Creating Private Certs ACM Private Certificate Authority - Mode-2 This workshop demonstrates how you create a AWS Certificate Manager private certificate authority and use this CA to create private X.509 certififcates for a private domain 40 mins 1 hour NOTE: The ACM PCA use cases (the latter 2) can only be run within the VPC where the ALB is deployed as a private DNS name space is used. This will work within the Cloud9 IDE but not from machines that are outside of the VPC.","title":"Workshops"},{"location":"#aws-initialization-tear-down","text":"IMPORTANT! This section is only relevant if you are not using a pre-provisioned account. The resources used in this workshop will incur charges in the AWS account used if not torn down according to the procedure outlined below You can use a personal account or create a new AWS account to ensure you have the neccessary access. This should not be an AWS account from the company you work for. Please note that creating an AWS account takes time (credit card validation, etc.) and is not recommended when participating in the workshop during a time constrained event.","title":"AWS Initialization &amp; tear down"},{"location":"#region-support","text":"Since these workshops use the Cloud9 IDE, you can use run these workshops in the following regions where the AWS Cloud9 service is available : N.Virginia (us-east-1) Ohio (us-east-2) Oregon (us-west-2) Ireland (eu-west-1) * Singapore (ap-southeast-1)","title":"Region Support"},{"location":"#cloudformation-templates-for-initial-environment-setup","text":"Please download the Data Protection Workshop cloudformation stack and launch it in your AWS account as this is required for all the workshops in this repository. To launch the stack you must go to the AWS Console and navigate to the CloudFormation service where you can choose Create Stack and upload the Cloudformation stack for the workshop. You provide a name for the stack and keep clicking next until you get to the point where it says: I acknowledge that AWS CloudFormation might create IAM resources with custom names. Acknowledge the above statement by clicking on the check box and then click on the Create button The above stack creates an Cloud9 IDE environment called workshop-environment . In addition a VPC with two subnets and an internet gateway is also created.","title":"Cloudformation templates for initial environment setup"},{"location":"#tear-down-cloudformation-stack","text":"After you have completed the workshop, you need to tear down the stack by navigating to the CloudFormation service in the AWS console and selecting the stack name you chose when launching the stack. Choose the delete action and wait for the process to complete. Note that it can take a few minutes for the stack to clean up its resources.","title":"Tear down Cloudformation stack"},{"location":"#license-summary","text":"This sample code is made available under a modified MIT license. See the LICENSE file.","title":"License Summary"},{"location":"contribute/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Finding contributions to work on Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security issue notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"contribute/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"contribute/#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"contribute/#contributing-via-pull-requests","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests"},{"location":"contribute/#finding-contributions-to-work-on","text":"Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.","title":"Finding contributions to work on"},{"location":"contribute/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"contribute/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security issue notifications"},{"location":"contribute/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"license/","text":"License MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"usecase-1/","text":"Server Side Encryption This workshop demonstrates server side encryption using AWS KMS and S3 Let's look at some concepts : Let's do some server side encryption Open the Cloud9 IDE environment called workshop-environment and navigate to the data-protection/usecase-1 directory. Follow the instructions below: 1. Run the module named kms_key_creation-Step-1.py This module will create a KMS master key with the key alias kms_key_sse_usecase_1 . In the following steps we will refer to this master key using the alias. Browse to the KMS console and you should find the key alias kms_key_sse_usecase_1 under customer managed keys 2. Run the module named usecase-1-Step-2.py This module uploads the plaintext_u.txt file to an S3 bucket named dp-workshop-builderXXXX . Before the file is stored on S3 it is server side encrypted using the KMS key alias kms_key_sse_usecase_1 3. Inspect the encrypted file in S3 In the AWS console, navigate to the S3 service and look for the bucket named dp-workshop-builderXXXX . In the bucket there should be a file called encrypted_e.txt . This file was encrypted using a Data key under the KMS master key key_sse_usecase_1 . Take a look at the properties of the file encrypted_e.txt . You will find that it's encrypted using AWS-KMS as shown in the picture below: 4. Compare the decrypted file from S3 with the original The usecase-1-Step-2.py python module does a S3 getobject API Call on encrypted_e.txt which is decrypted by the S3 service and retrieved over TLS into your Cloud9 environment. In the folder usecase-1 ,you should see a file called plaintext_cycled_u.txt . Compare its contents to the original file named plaintext_u.txt . 5. Run the module named usecase-1-cleanup-Step-3.py This modules deletes the kms key and it's alias that we created in kms_key_creation-Step-1.py and also deletes all the files that were created in the usecase-1 folder. Please remember that when you run usecase-1-cleanup-Step-3.py and you want to re-run this use case, you will have to start from the beginning.","title":"Home"},{"location":"usecase-1/#server-side-encryption","text":"This workshop demonstrates server side encryption using AWS KMS and S3","title":"Server Side Encryption"},{"location":"usecase-1/#lets-look-at-some-concepts","text":"","title":"Let's look at some concepts :"},{"location":"usecase-1/#lets-do-some-server-side-encryption","text":"Open the Cloud9 IDE environment called workshop-environment and navigate to the data-protection/usecase-1 directory. Follow the instructions below:","title":"Let's do some server side encryption"},{"location":"usecase-1/#1-run-the-module-named-kms_key_creation-step-1py","text":"This module will create a KMS master key with the key alias kms_key_sse_usecase_1 . In the following steps we will refer to this master key using the alias. Browse to the KMS console and you should find the key alias kms_key_sse_usecase_1 under customer managed keys","title":"1. Run the module named kms_key_creation-Step-1.py"},{"location":"usecase-1/#2-run-the-module-named-usecase-1-step-2py","text":"This module uploads the plaintext_u.txt file to an S3 bucket named dp-workshop-builderXXXX . Before the file is stored on S3 it is server side encrypted using the KMS key alias kms_key_sse_usecase_1","title":"2. Run the module named usecase-1-Step-2.py"},{"location":"usecase-1/#3-inspect-the-encrypted-file-in-s3","text":"In the AWS console, navigate to the S3 service and look for the bucket named dp-workshop-builderXXXX . In the bucket there should be a file called encrypted_e.txt . This file was encrypted using a Data key under the KMS master key key_sse_usecase_1 . Take a look at the properties of the file encrypted_e.txt . You will find that it's encrypted using AWS-KMS as shown in the picture below:","title":"3. Inspect the encrypted file in S3"},{"location":"usecase-1/#4-compare-the-decrypted-file-from-s3-with-the-original","text":"The usecase-1-Step-2.py python module does a S3 getobject API Call on encrypted_e.txt which is decrypted by the S3 service and retrieved over TLS into your Cloud9 environment. In the folder usecase-1 ,you should see a file called plaintext_cycled_u.txt . Compare its contents to the original file named plaintext_u.txt .","title":"4. Compare the decrypted file from S3 with the original"},{"location":"usecase-1/#5-run-the-module-named-usecase-1-cleanup-step-3py","text":"This modules deletes the kms key and it's alias that we created in kms_key_creation-Step-1.py and also deletes all the files that were created in the usecase-1 folder. Please remember that when you run usecase-1-cleanup-Step-3.py and you want to re-run this use case, you will have to start from the beginning.","title":"5. Run the module named usecase-1-cleanup-Step-3.py"},{"location":"usecase-2/","text":"Client Side Encryption This workshop demonstrates client side encryption Let's do some client side encryption Open the Cloud9 IDE environment called workshop-environment and navigate to the data-protection/usecase-2 directory. Follow the steps below: 1. Run the module named kms_key_creation-Step-1.py You should see \"KMS Master Key with alias name kms_key_cse_usecase_3 successfully created\" printed in the runner window pane below. This python module will create a KMS master key with the key alias kms_key_cse_usecase_2 Browse to the KMS console and you should find the key alias kms_key_cse_usecase_2 under customer managed keys 2. Run the usecase-2-Step-2.py python module . The runner pane should print \"Module run was successful !!\" You will find a file called plaintext_u.txt which is the plaintext unencrypted file The module usecase-2-Step-2.py encrypts the plaintext_u.txt file The encrypted file is created and is called encrypted_e.txt You should see \"Module run was successful\" printed in the runner window pane below 3. Check the decrypted file The encrypted file encrypted_e.txt is then decrypted The decrypted file is called plaintext_u_cycled.txt 4. Check whether the encryption and decryption process was successful Check whether the plaintext_u.txt and plaintext_u_cycled.txt have the same content This indicates that the client side encryption and then decryption was successful 5. Run the check-gendatakey-Step-3.py python module Wait for 2 minutes Run the check-gendatakey-Step-3.py python module The check-gendatakey-Step-3.py is checking for whether a GenerateDataKey API call was logged by cloudtrail and this event was then sent to a cloudwatch event rule. If all things go well, you should see \"GenerateDataKey API Called\" in the runner window below. If you don'things see this print wait for a minute and try again 6. Run the usecase-2-cleanup-Step-4.py python module You should see Cleanup Successful printed in the runner window pane below This modules deletes the kms key and it's alias that we created in kms_key_creation-Step-1.py .It also deletes all the files that were created in the usecase-2 folder Please remember that every time you run usecase-2-cleanup-Step-4.py ,if you want to re-run this uecase, you will have to start from Step 1 Some questions to think about : Why do we wait for 2 minutes in Step 5 ?","title":"Home"},{"location":"usecase-2/#client-side-encryption","text":"This workshop demonstrates client side encryption","title":"Client Side Encryption"},{"location":"usecase-2/#lets-do-some-client-side-encryption","text":"Open the Cloud9 IDE environment called workshop-environment and navigate to the data-protection/usecase-2 directory. Follow the steps below:","title":"Let's do some client side encryption"},{"location":"usecase-2/#1-run-the-module-named-kms_key_creation-step-1py","text":"You should see \"KMS Master Key with alias name kms_key_cse_usecase_3 successfully created\" printed in the runner window pane below. This python module will create a KMS master key with the key alias kms_key_cse_usecase_2 Browse to the KMS console and you should find the key alias kms_key_cse_usecase_2 under customer managed keys","title":"1. Run the module named kms_key_creation-Step-1.py"},{"location":"usecase-2/#2-run-the-usecase-2-step-2py-python-module","text":"The runner pane should print \"Module run was successful !!\" You will find a file called plaintext_u.txt which is the plaintext unencrypted file The module usecase-2-Step-2.py encrypts the plaintext_u.txt file The encrypted file is created and is called encrypted_e.txt You should see \"Module run was successful\" printed in the runner window pane below","title":"2. Run the usecase-2-Step-2.py python module ."},{"location":"usecase-2/#3-check-the-decrypted-file","text":"The encrypted file encrypted_e.txt is then decrypted The decrypted file is called plaintext_u_cycled.txt","title":"3. Check the decrypted file"},{"location":"usecase-2/#4-check-whether-the-encryption-and-decryption-process-was-successful","text":"Check whether the plaintext_u.txt and plaintext_u_cycled.txt have the same content This indicates that the client side encryption and then decryption was successful","title":"4. Check whether the encryption and decryption process was successful"},{"location":"usecase-2/#5-run-the-check-gendatakey-step-3py-python-module","text":"Wait for 2 minutes Run the check-gendatakey-Step-3.py python module The check-gendatakey-Step-3.py is checking for whether a GenerateDataKey API call was logged by cloudtrail and this event was then sent to a cloudwatch event rule. If all things go well, you should see \"GenerateDataKey API Called\" in the runner window below. If you don'things see this print wait for a minute and try again","title":"5. Run the check-gendatakey-Step-3.py python module"},{"location":"usecase-2/#6-run-the-usecase-2-cleanup-step-4py-python-module","text":"You should see Cleanup Successful printed in the runner window pane below This modules deletes the kms key and it's alias that we created in kms_key_creation-Step-1.py .It also deletes all the files that were created in the usecase-2 folder Please remember that every time you run usecase-2-cleanup-Step-4.py ,if you want to re-run this uecase, you will have to start from Step 1","title":"6. Run the usecase-2-cleanup-Step-4.py python module"},{"location":"usecase-2/#some-questions-to-think-about","text":"Why do we wait for 2 minutes in Step 5 ?","title":"Some questions to think about :"},{"location":"usecase-3/","text":"Client Side Encryption This workshop demonstrates client side encryption with data key caching Let's do some client side encryption with data key caching Open the Cloud9 IDE environment called workshop-environment and navigate to the data-protection/usecase-3 directory. Follow the steps below: Step 1 : Run the module named kms_key_creation-Step-1.py in the folder usecase-3 You should see \"KMS Master Key with alias name kms_key_cse_usecase_3 successfully created\" printed in the runner window pane below. This python module will create a KMS master key with the key alias kms_key_cse_usecase_3 Browse to the KMS console and you should find the key alias kms_key_cse_usecase_3 under customer managed keys Step 2 : You will find a file called plaintext_u.txt which is the plaintext unencrypted file. Run the usecase-3-Step-2.py python module. The module usecase-3-Step-2.py encrypts the plaintext_u.txt file and produces an encrypted file called encrypted_e_1.txt The plaintext_u.txt file is encrypted one more time and an encrypted file called encrypted_e_2.txt is produced You should see \"Module run was successful\" printed in the runner window pane below Step 3 : The encrypted file encrypted_e_1.txt is then decrypted and the decrypted file is called plaintext_u_cycled_1.txt The encrypted file encrypted_e_2.txt is then decrypted andthe decrypted file is called plaintext_u_cycled_2.txt Step 4 : Wait for 2 minutes Run the check-gendatakey-Step-3.py python module You should see \"GenerateDataKey API Called\" printed in the runner window pane below Even though in Step 3 two encrypts happened only one GenerateDataKey API call was made. The reason for this is that the data key that was generated was cached and reused for the second encrypt call Open up usecase-3-Step-2.py and take a look at both the encrypt calls in the code Step 5 : Run usecase-3-cleanup-Step-4.py python module You should see Cleanup Successful printed in the runner window pane below This modules deletes the kms key and it's alias that we created in kms_key_creation-Step-1.py .It also deletes all the files that were created as part of the module run in the usecase-3 folder Please remember that every time you run usecase-3-cleanup-Step-4.py ,if you want to re-run this uecase, you will have to start from Step 1 Some questions to think about : Why do we wait for 2 minutes in Step 4 ? When you run the python module check-gendatakey-Step-3.py should you see prints for one GenerateDataKey API call or two GenerateDataKey API calls ?","title":"Home"},{"location":"usecase-3/#client-side-encryption","text":"This workshop demonstrates client side encryption with data key caching","title":"Client Side Encryption"},{"location":"usecase-3/#lets-do-some-client-side-encryption-with-data-key-caching","text":"Open the Cloud9 IDE environment called workshop-environment and navigate to the data-protection/usecase-3 directory. Follow the steps below:","title":"Let's do some client side encryption with data key caching"},{"location":"usecase-3/#step-1","text":"Run the module named kms_key_creation-Step-1.py in the folder usecase-3 You should see \"KMS Master Key with alias name kms_key_cse_usecase_3 successfully created\" printed in the runner window pane below. This python module will create a KMS master key with the key alias kms_key_cse_usecase_3 Browse to the KMS console and you should find the key alias kms_key_cse_usecase_3 under customer managed keys","title":"Step 1 :"},{"location":"usecase-3/#step-2","text":"You will find a file called plaintext_u.txt which is the plaintext unencrypted file. Run the usecase-3-Step-2.py python module. The module usecase-3-Step-2.py encrypts the plaintext_u.txt file and produces an encrypted file called encrypted_e_1.txt The plaintext_u.txt file is encrypted one more time and an encrypted file called encrypted_e_2.txt is produced You should see \"Module run was successful\" printed in the runner window pane below","title":"Step 2 :"},{"location":"usecase-3/#step-3","text":"The encrypted file encrypted_e_1.txt is then decrypted and the decrypted file is called plaintext_u_cycled_1.txt The encrypted file encrypted_e_2.txt is then decrypted andthe decrypted file is called plaintext_u_cycled_2.txt","title":"Step 3 :"},{"location":"usecase-3/#step-4","text":"Wait for 2 minutes Run the check-gendatakey-Step-3.py python module You should see \"GenerateDataKey API Called\" printed in the runner window pane below Even though in Step 3 two encrypts happened only one GenerateDataKey API call was made. The reason for this is that the data key that was generated was cached and reused for the second encrypt call Open up usecase-3-Step-2.py and take a look at both the encrypt calls in the code","title":"Step 4 :"},{"location":"usecase-3/#step-5","text":"Run usecase-3-cleanup-Step-4.py python module You should see Cleanup Successful printed in the runner window pane below This modules deletes the kms key and it's alias that we created in kms_key_creation-Step-1.py .It also deletes all the files that were created as part of the module run in the usecase-3 folder Please remember that every time you run usecase-3-cleanup-Step-4.py ,if you want to re-run this uecase, you will have to start from Step 1","title":"Step 5 :"},{"location":"usecase-3/#some-questions-to-think-about","text":"Why do we wait for 2 minutes in Step 4 ? When you run the python module check-gendatakey-Step-3.py should you see prints for one GenerateDataKey API call or two GenerateDataKey API calls ?","title":"Some questions to think about :"},{"location":"usecase-4/","text":"ACM Private Certificate authority - Private certs for your webserver This workshop demonstrates how ACM Private Certificate authority(PCA) can be created and made operational. It also helps you learn about how ACM PCA can be used to generate private certificates for your devices or web servers. In this usecase you will generate a CSR(certificate signing request) for your device or server and then get it signed by the AWS Certificate manager private CA Let's look at some concepts : Let's do some private cert generaton with AWS Certificate Manager(ACM) private certificate authority(PCA) : Open the Cloud9 IDE environment called workshop-environment and navigate to the data-protection/usecase-4 directory. Follow the instructions below: Step 1 : Run the python module named usecase-4-step-1.py First you will see Pending DynamoDB table creation for storing shared variables printed on the runner window pane below Wait for about 45 seconds You should see shared_variables_crypto_builders DynamoDB table created printed This module will create a DynamoDB table called shared_variables_crypto_builders . The primary purpose of this table is to share variables across the different python modules that we will run in this usecase. Step 2 : Run the python module named usecase-4-step-2.py This module creates a ACM private certificate authority with the common name acmpcausecase4.subordinate This private certificate authority will publish certificate revocation lists within a S3 bucket whose name starts with builder-acm-pca-usecase-4-bucket-pca-crl You should see the following printed in the runner window pane Private CA has been created Please generate the CSR and get it signed by your organizations's root cert Success : The ARN of the subordinate private certificate authority is : arn:aws:acm-pca: : :certificate-authority/57943599-30d2-8723-1234-1cb4b7d81128 In the AWS console browse to the AWS Certificate Manager service(ACM) . Under Private CA's you will see the private CA created and the status should show \"Pending Certificate\" Some questions to think about : Why is the status of the private CA showing \"Pending Certificate\" ? Is the private certificate authority that's created a root CA or a subordinate CA ? What's the purpose of the S3 bucket storing certificate revocation lists ? Step 3 : Run the python module named usecase-4-step-3.py This module creates a self signed root certificate with the common name rootca-builder You can see in the code that the private key associated with the self signed cert is stored in an encrypted DynamoDB table. This is purely for demonstration purposes. In your organization you should store it in an HSM or a secure vault You should see the following printed in the runner window pane below Success - Self signed certificate file self-signed-cert.pem created\" This self signed certificate will be used in the certificate chain of trust Some questions to think about : In your organization would you use the root cert to sign subordinate CA's ? Why is it necessary to store the private keys of root certs in an HSM ? What would happen if the private key of the root cert gets compromised or stolen ? Step 4 : Run the python module named usecase-4-step-4.py This module gets a Certificate signing request(CSR) for the private certifiate authority with common name acmpcausecas4.subordinate that was created in Step 2 The certificate signing request is signed using the self signed certificate and it's private key that was created in Step 3 The signed cert is stored in a pem file called signed_subordinate_ca_cert.pem You should see the following printed in the runner window pane below Successfully created signed subordinate CA pem file signed_subordinate_ca_cert.pem Step 5 : Run the python module named usecase-4-step-5.py This module imports the subordinate CA signed certificate signed_subordinate_ca_cert.pem and the certificate chain of trust into AWS Certificate Manager(ACM) The certificate chain contains the self signed or root CA certificate that we created in Step 3 After this operation the subordinate private certificate authority(CA) changes status to ACTIVE. Browse to the ACM service within the AWS console and you should see the status of the subordiate CA with common name acmpcausecase4.subordinate as ACTIVE as shown below We are at a point where the subordinate private certificate authority(PCA) can issue private certificates for any endpoint, device or server You should see the following printed in the runner window pane below Successfully imported signed cert and certificate chain into ACM Step 6 : Time : 2 minutes Run the python module named usecase-4-step-6.py This module takes about 2 minutes to complete This module creates a CSR for a webserver endpoint with common name 127.0.0.1 and the CSR is then passed to the issue_certificate API call which sends the CSR to AWS Certificate Manager and is signed by the subordinate private certificate authority The signed webserver endpoint certificate pem file is called \"webserver_cert.pem\" The issue_certificate API calls also returns the certificate chain of trust and the pem file that stores the certificate chain of trust is called \"webserver_cert_chain.pem\" You should see the following printed in the runner window pane below Successfully created server certificate webserver_cert.pem for the flask web server Successfully created chain of trust webserver_cert_chain.pem for the flask web server Step 7 : Run the python module named usecase-4-step-7.py This module creates a python flask web server The webserver is running within the Cloud9 environment and is exposed through the following URL https://127.0.0.1:5000/ on port 5000 You should see the following printed in the runner window pane below Running on https://127.0.0.1:5000/ For the next steps this webserver needs to keep running. So please don't kill the runner window pane tab Step 8 : Run the python module named usecase-4-step-8.py This module uses the below curl command to do a HTTP GET on the flask webserver created in Step 7 curl --verbose -X GET https://127.0.0.1:5000/ We are using the curl command to simulate a HTTPS web client Since the curl commmand does not supply the certificate trust chain as a parameter the HTTPS connection is going to complain that the server certificate is not recognized. You will see the following printed in the runner window pane below if you look through the printed log curl: (60) Peer's Certificate issuer is not recognized Certificate is not trusted - cannot validate server certificate Some questions to think about : Why was the server certificate not recognized by the curl command ? Step 9 : Run the python module named usecase-4-step-9.py This module uses curl to do a HTTPS GET on the flask webserver created in Step 7 using the following command : curl --verbose --cacert 'webserver_cert_chain.pem' -X GET https://127.0.0.1:5000/ Since the curl command has the chain of trust pem file as a parameter the flask webserver certificate is successfully authenticated and you should see the following printed in the runner window pane. Hello World! Certificate is trusted and is valid Step 9 : Run the python module named usecase-4-step-10-cleanup.py This module cleans up all the resources that were created as part of this usecase Please make sure that you run this cleanup script. Otherwise you will continue accruing charges for the ACM private certificate authority that was created during this usecase","title":"Home"},{"location":"usecase-4/#acm-private-certificate-authority-private-certs-for-your-webserver","text":"This workshop demonstrates how ACM Private Certificate authority(PCA) can be created and made operational. It also helps you learn about how ACM PCA can be used to generate private certificates for your devices or web servers. In this usecase you will generate a CSR(certificate signing request) for your device or server and then get it signed by the AWS Certificate manager private CA","title":"ACM Private Certificate authority - Private certs for your webserver"},{"location":"usecase-4/#lets-look-at-some-concepts","text":"","title":"Let's look at some concepts :"},{"location":"usecase-4/#lets-do-some-private-cert-generaton-with-aws-certificate-manageracm-private-certificate-authoritypca","text":"Open the Cloud9 IDE environment called workshop-environment and navigate to the data-protection/usecase-4 directory. Follow the instructions below:","title":"Let's do some private cert generaton with AWS Certificate Manager(ACM) private certificate authority(PCA) :"},{"location":"usecase-4/#step-1","text":"Run the python module named usecase-4-step-1.py First you will see Pending DynamoDB table creation for storing shared variables printed on the runner window pane below Wait for about 45 seconds You should see shared_variables_crypto_builders DynamoDB table created printed This module will create a DynamoDB table called shared_variables_crypto_builders . The primary purpose of this table is to share variables across the different python modules that we will run in this usecase.","title":"Step 1 :"},{"location":"usecase-4/#step-2","text":"Run the python module named usecase-4-step-2.py This module creates a ACM private certificate authority with the common name acmpcausecase4.subordinate This private certificate authority will publish certificate revocation lists within a S3 bucket whose name starts with builder-acm-pca-usecase-4-bucket-pca-crl You should see the following printed in the runner window pane Private CA has been created Please generate the CSR and get it signed by your organizations's root cert Success : The ARN of the subordinate private certificate authority is : arn:aws:acm-pca: : :certificate-authority/57943599-30d2-8723-1234-1cb4b7d81128 In the AWS console browse to the AWS Certificate Manager service(ACM) . Under Private CA's you will see the private CA created and the status should show \"Pending Certificate\" Some questions to think about : Why is the status of the private CA showing \"Pending Certificate\" ? Is the private certificate authority that's created a root CA or a subordinate CA ? What's the purpose of the S3 bucket storing certificate revocation lists ?","title":"Step 2 :"},{"location":"usecase-4/#step-3","text":"Run the python module named usecase-4-step-3.py This module creates a self signed root certificate with the common name rootca-builder You can see in the code that the private key associated with the self signed cert is stored in an encrypted DynamoDB table. This is purely for demonstration purposes. In your organization you should store it in an HSM or a secure vault You should see the following printed in the runner window pane below Success - Self signed certificate file self-signed-cert.pem created\" This self signed certificate will be used in the certificate chain of trust Some questions to think about : In your organization would you use the root cert to sign subordinate CA's ? Why is it necessary to store the private keys of root certs in an HSM ? What would happen if the private key of the root cert gets compromised or stolen ?","title":"Step 3 :"},{"location":"usecase-4/#step-4","text":"Run the python module named usecase-4-step-4.py This module gets a Certificate signing request(CSR) for the private certifiate authority with common name acmpcausecas4.subordinate that was created in Step 2 The certificate signing request is signed using the self signed certificate and it's private key that was created in Step 3 The signed cert is stored in a pem file called signed_subordinate_ca_cert.pem You should see the following printed in the runner window pane below Successfully created signed subordinate CA pem file signed_subordinate_ca_cert.pem","title":"Step 4 :"},{"location":"usecase-4/#step-5","text":"Run the python module named usecase-4-step-5.py This module imports the subordinate CA signed certificate signed_subordinate_ca_cert.pem and the certificate chain of trust into AWS Certificate Manager(ACM) The certificate chain contains the self signed or root CA certificate that we created in Step 3 After this operation the subordinate private certificate authority(CA) changes status to ACTIVE. Browse to the ACM service within the AWS console and you should see the status of the subordiate CA with common name acmpcausecase4.subordinate as ACTIVE as shown below We are at a point where the subordinate private certificate authority(PCA) can issue private certificates for any endpoint, device or server You should see the following printed in the runner window pane below Successfully imported signed cert and certificate chain into ACM","title":"Step 5 :"},{"location":"usecase-4/#step-6","text":"Time : 2 minutes Run the python module named usecase-4-step-6.py This module takes about 2 minutes to complete This module creates a CSR for a webserver endpoint with common name 127.0.0.1 and the CSR is then passed to the issue_certificate API call which sends the CSR to AWS Certificate Manager and is signed by the subordinate private certificate authority The signed webserver endpoint certificate pem file is called \"webserver_cert.pem\" The issue_certificate API calls also returns the certificate chain of trust and the pem file that stores the certificate chain of trust is called \"webserver_cert_chain.pem\" You should see the following printed in the runner window pane below Successfully created server certificate webserver_cert.pem for the flask web server Successfully created chain of trust webserver_cert_chain.pem for the flask web server","title":"Step 6 :"},{"location":"usecase-4/#step-7","text":"Run the python module named usecase-4-step-7.py This module creates a python flask web server The webserver is running within the Cloud9 environment and is exposed through the following URL https://127.0.0.1:5000/ on port 5000 You should see the following printed in the runner window pane below Running on https://127.0.0.1:5000/ For the next steps this webserver needs to keep running. So please don't kill the runner window pane tab","title":"Step 7 :"},{"location":"usecase-4/#step-8","text":"Run the python module named usecase-4-step-8.py This module uses the below curl command to do a HTTP GET on the flask webserver created in Step 7 curl --verbose -X GET https://127.0.0.1:5000/ We are using the curl command to simulate a HTTPS web client Since the curl commmand does not supply the certificate trust chain as a parameter the HTTPS connection is going to complain that the server certificate is not recognized. You will see the following printed in the runner window pane below if you look through the printed log curl: (60) Peer's Certificate issuer is not recognized Certificate is not trusted - cannot validate server certificate Some questions to think about : Why was the server certificate not recognized by the curl command ?","title":"Step 8 :"},{"location":"usecase-4/#step-9","text":"Run the python module named usecase-4-step-9.py This module uses curl to do a HTTPS GET on the flask webserver created in Step 7 using the following command : curl --verbose --cacert 'webserver_cert_chain.pem' -X GET https://127.0.0.1:5000/ Since the curl command has the chain of trust pem file as a parameter the flask webserver certificate is successfully authenticated and you should see the following printed in the runner window pane. Hello World! Certificate is trusted and is valid","title":"Step 9 :"},{"location":"usecase-4/#step-9_1","text":"Run the python module named usecase-4-step-10-cleanup.py This module cleans up all the resources that were created as part of this usecase Please make sure that you run this cleanup script. Otherwise you will continue accruing charges for the ACM private certificate authority that was created during this usecase","title":"Step 9 :"},{"location":"usecase-5/","text":"AWS Data Protection Workshops If you are considering protecting data in your AWS environment using methods such as encryption or certificate management, these workshops can help you learn in depth. We will be using the Cloud9 IDE environment and a combination of Python code and AWS console access for these workshops. Ubiquitous Encryption Data encryption provides a strong layer of security to protect data that you store within AWS services. AWS services can help you achieve ubiquitous encryption for data in transit as well as data at rest. Prerequisites AWS Account If you are participating in this workshop as part of an AWS event, pre-provisioned temporary accounts that are specifically initialized for this workshop might be provided by the organizers. To access your temporary account you will receive a 12-digit hash code that can be used at the AWS Event Engine Site . You will not need a username and password. If you wish to participate in this workshop without a pre-provisioned temporary account, please see the AWS Initialization and tear down section below. Browser These workshops assume that you are using the Cloud9 IDE environment . We recommend you use the latest version of Chrome or Firefox to complete this workshop. Knowledge Of Python Programming Language Basic python knowledge is sufficient to consume these workshops. Setup Workshop Environment Navigate to the Cloud9 service within your AWS console Open the Cloud9 IDE environment called workshop-environment . It takes about 30 seconds for the environment to start up. In the Cloud9 IDE environment you will find a folder called data-protection in the folder pane on the left side of the screen Right-click (on MacOS: control-click) the file named environment-setup.sh in the IDE and select Run This script takes about a minute to complete In the runner window below you should see SUCCESS: installed python dependencies followed by a list of the installed packages Workshops These workshops demonstrates server side encryption, client side encryption and certfificate management concepts within AWS. For example : How do I put an object on S3 with server side encryption ? How do I use aws encryption sdk to encrypt data in my application before sending the data to an AWS service ? What is Data Key Caching ? How can I generate X.509 certificates with AWS Certificate Manager to enable TLS on my load balancer ? How do I use AWS Certificate Manager to generate a private certificate authority ? Title Description Learning Time Teaching Time With Discussion Level 200: Server Side Encryption This workshop demonstrates server side encryption on S3 15 min 30 min Level 200: Client Side Encryption This workshop demonstrates client side encryption 15 min 30 min Level 200: Client Side Encryption With Data Key Caching This workshop demonstrates client side encryption with data key caching 15 min 30 min Level 300: Creating Private Certs ACM Private Certificate Authority - Mode-1 This workshop demonstrates how you create a AWS Certificate Manager private certificate authority(PCA) and use ACM PCA to sign a CSR to create a private certificate 40 mins 1 hour Level 300: Creating Private Certs ACM Private Certificate Authority - Mode-2 This workshop demonstrates how you create a AWS Certificate Manager private certificate authority and use this CA to create private X.509 certififcates for a private domain 40 mins 1 hour NOTE: The ACM PCA use cases (the latter 2) can only be run within the VPC where the ALB is deployed as a private DNS name space is used. This will work within the Cloud9 IDE but not from machines that are outside of the VPC. AWS Initialization tear down IMPORTANT! This section is only relevant if you are not using a pre-provisioned account. The resources used in this workshop will incur charges in the AWS account used if not torn down according to the procedure outlined below You can use a personal account or create a new AWS account to ensure you have the neccessary access. This should not be an AWS account from the company you work for. Please note that creating an AWS account takes time (credit card validation, etc.) and is not recommended when participating in the workshop during a time constrained event. Region Support Since these workshops use the Cloud9 IDE, you can use run these workshops in the following regions where the AWS Cloud9 service is available : N.Virginia (us-east-1) Ohio (us-east-2) Oregon (us-west-2) Ireland (eu-west-1) * Singapore (ap-southeast-1) Cloudformation templates for initial environment setup Please download the Data Protection Workshop cloudformation stack and launch it in your AWS account as this is required for all the workshops in this repository. To launch the stack you must go to the AWS Console and navigate to the CloudFormation service where you can choose Create Stack and upload the Cloudformation stack for the workshop. You provide a name for the stack and keep clicking next until you get to the point where it says: I acknowledge that AWS CloudFormation might create IAM resources with custom names. Acknowledge the above statement by clicking on the check box and then click on the Create button The above stack creates an Cloud9 IDE environment called workshop-environment . In addition a VPC with two subnets and an internet gateway is also created. Tear down Cloudformation stack After you have completed the workshop, you need to tear down the stack by navigating to the CloudFormation service in the AWS console and selecting the stack name you chose when launching the stack. Choose the delete action and wait for the process to complete. Note that it can take a few minutes for the stack to clean up its resources. License Summary This sample code is made available under a modified MIT license. See the LICENSE file.","title":"AWS Data Protection Workshops"},{"location":"usecase-5/#aws-data-protection-workshops","text":"If you are considering protecting data in your AWS environment using methods such as encryption or certificate management, these workshops can help you learn in depth. We will be using the Cloud9 IDE environment and a combination of Python code and AWS console access for these workshops.","title":"AWS Data Protection Workshops"},{"location":"usecase-5/#ubiquitous-encryption","text":"Data encryption provides a strong layer of security to protect data that you store within AWS services. AWS services can help you achieve ubiquitous encryption for data in transit as well as data at rest.","title":"Ubiquitous Encryption"},{"location":"usecase-5/#prerequisites","text":"","title":"Prerequisites"},{"location":"usecase-5/#aws-account","text":"If you are participating in this workshop as part of an AWS event, pre-provisioned temporary accounts that are specifically initialized for this workshop might be provided by the organizers. To access your temporary account you will receive a 12-digit hash code that can be used at the AWS Event Engine Site . You will not need a username and password. If you wish to participate in this workshop without a pre-provisioned temporary account, please see the AWS Initialization and tear down section below.","title":"AWS Account"},{"location":"usecase-5/#browser","text":"These workshops assume that you are using the Cloud9 IDE environment . We recommend you use the latest version of Chrome or Firefox to complete this workshop.","title":"Browser"},{"location":"usecase-5/#knowledge-of-python-programming-language","text":"Basic python knowledge is sufficient to consume these workshops.","title":"Knowledge Of Python Programming Language"},{"location":"usecase-5/#setup-workshop-environment","text":"Navigate to the Cloud9 service within your AWS console Open the Cloud9 IDE environment called workshop-environment . It takes about 30 seconds for the environment to start up. In the Cloud9 IDE environment you will find a folder called data-protection in the folder pane on the left side of the screen Right-click (on MacOS: control-click) the file named environment-setup.sh in the IDE and select Run This script takes about a minute to complete In the runner window below you should see SUCCESS: installed python dependencies followed by a list of the installed packages","title":"Setup Workshop Environment"},{"location":"usecase-5/#workshops","text":"These workshops demonstrates server side encryption, client side encryption and certfificate management concepts within AWS. For example : How do I put an object on S3 with server side encryption ? How do I use aws encryption sdk to encrypt data in my application before sending the data to an AWS service ? What is Data Key Caching ? How can I generate X.509 certificates with AWS Certificate Manager to enable TLS on my load balancer ? How do I use AWS Certificate Manager to generate a private certificate authority ? Title Description Learning Time Teaching Time With Discussion Level 200: Server Side Encryption This workshop demonstrates server side encryption on S3 15 min 30 min Level 200: Client Side Encryption This workshop demonstrates client side encryption 15 min 30 min Level 200: Client Side Encryption With Data Key Caching This workshop demonstrates client side encryption with data key caching 15 min 30 min Level 300: Creating Private Certs ACM Private Certificate Authority - Mode-1 This workshop demonstrates how you create a AWS Certificate Manager private certificate authority(PCA) and use ACM PCA to sign a CSR to create a private certificate 40 mins 1 hour Level 300: Creating Private Certs ACM Private Certificate Authority - Mode-2 This workshop demonstrates how you create a AWS Certificate Manager private certificate authority and use this CA to create private X.509 certififcates for a private domain 40 mins 1 hour NOTE: The ACM PCA use cases (the latter 2) can only be run within the VPC where the ALB is deployed as a private DNS name space is used. This will work within the Cloud9 IDE but not from machines that are outside of the VPC.","title":"Workshops"},{"location":"usecase-5/#aws-initialization-tear-down","text":"IMPORTANT! This section is only relevant if you are not using a pre-provisioned account. The resources used in this workshop will incur charges in the AWS account used if not torn down according to the procedure outlined below You can use a personal account or create a new AWS account to ensure you have the neccessary access. This should not be an AWS account from the company you work for. Please note that creating an AWS account takes time (credit card validation, etc.) and is not recommended when participating in the workshop during a time constrained event.","title":"AWS Initialization &amp; tear down"},{"location":"usecase-5/#region-support","text":"Since these workshops use the Cloud9 IDE, you can use run these workshops in the following regions where the AWS Cloud9 service is available : N.Virginia (us-east-1) Ohio (us-east-2) Oregon (us-west-2) Ireland (eu-west-1) * Singapore (ap-southeast-1)","title":"Region Support"},{"location":"usecase-5/#cloudformation-templates-for-initial-environment-setup","text":"Please download the Data Protection Workshop cloudformation stack and launch it in your AWS account as this is required for all the workshops in this repository. To launch the stack you must go to the AWS Console and navigate to the CloudFormation service where you can choose Create Stack and upload the Cloudformation stack for the workshop. You provide a name for the stack and keep clicking next until you get to the point where it says: I acknowledge that AWS CloudFormation might create IAM resources with custom names. Acknowledge the above statement by clicking on the check box and then click on the Create button The above stack creates an Cloud9 IDE environment called workshop-environment . In addition a VPC with two subnets and an internet gateway is also created.","title":"Cloudformation templates for initial environment setup"},{"location":"usecase-5/#tear-down-cloudformation-stack","text":"After you have completed the workshop, you need to tear down the stack by navigating to the CloudFormation service in the AWS console and selecting the stack name you chose when launching the stack. Choose the delete action and wait for the process to complete. Note that it can take a few minutes for the stack to clean up its resources.","title":"Tear down Cloudformation stack"},{"location":"usecase-5/#license-summary","text":"This sample code is made available under a modified MIT license. See the LICENSE file.","title":"License Summary"}]}